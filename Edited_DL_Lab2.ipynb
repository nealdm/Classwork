{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b2iKwXORd9B4"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/wingated/cs474_labs_f2019/blob/master/DL_Lab2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "# Lab 2: Intro to PyTorch\n",
    "\n",
    "## Deliverable\n",
    "\n",
    "For this lab, you will submit an ipython notebook via learningsuite.\n",
    "This lab will be mostly boilerplate code, but you will be required to implement a few extras.\n",
    "\n",
    "**NOTE: you almost certainly will not understand most of what's going on in this lab!\n",
    "That's ok - the point is just to get you going with pytorch.\n",
    "We'll be working on developing a deeper understanding of every part of this code\n",
    "over the course of the next two weeks.**\n",
    "\n",
    "A major goal of this lab is to help you become conversant in working through pytorch\n",
    "tutorials and documentation.\n",
    "So, you should feel free to google whatever you want and need!\n",
    "\n",
    "This notebook will have three parts:\n",
    "\n",
    "* Part 1: Your notebook should contain the boilerplate code. See below.\n",
    "\n",
    "* Part 2: Your notebook should extend the boilerplate code by adding a testing loop.\n",
    "\n",
    "* Part 3: Your notebook should extend the boilerplate code by adding a visualization of test/training performance over time.\n",
    "\n",
    "The resulting image could, for example, look like this:\n",
    "![](http://liftothers.org/dokuwiki/lib/exe/fetch.php?cache=&w=900&h=608&tok=3092fe&media=cs501r_f2018:lab2.png)\n",
    "See the assigned readings for pointers to documentation on pytorch.\n",
    "___\n",
    "\n",
    "### Grading standards:\n",
    "Your notebook will be graded on the following:\n",
    "\n",
    "* 50% Successfully followed lab video and typed in code\n",
    "* 20% Modified code to include a test/train split\n",
    "* 20% Modified code to include a visualization of train/test losses\n",
    "* 10% Tidy and legible figures, including labeled axes where appropriate\n",
    "___\n",
    "\n",
    "### Description\n",
    "Throughout this class, we will be using pytorch to implement our deep neural networks. \n",
    "Pytorch is a deep learning framework that handles the low-level details of \n",
    "GPU integration and automatic differentiation.\n",
    "\n",
    "The goal of this lab is to help you become familiar with pytorch. \n",
    "The three parts of the lab are outlined above.\n",
    "\n",
    "For part 1, you should watch the video below, and type in the code as it is explained to you.\n",
    "\n",
    "A more detailed outline of Part 1 is below.\n",
    "\n",
    "For part 2, you must add a validation (or testing) loop using the \n",
    "FashionMNIST dataset with train=False\n",
    "\n",
    "For part 3, you must plot the loss values and demonstrate overfitting.\n",
    "\n",
    "The easiest way to do this is to limit the size of your training dataset \n",
    "so that it only returns a single batch (ie len(dataloader) == batch_size, \n",
    "and train for multiple epochs. In the example graph above, \n",
    "I set my batch size to 42, and augmented my dataloader to produce only 42 \n",
    "unique items by overwriting the len function to return 42. \n",
    "In my training loop, I performed a validation every epoch which basically corresponded \n",
    "to a validation every step.\n",
    "\n",
    "In practice, you will normally compute your validation loss every n steps, \n",
    "rather than at the end of every epoch. This is because some epochs can take hours, \n",
    "or even days and you donâ€™t often want to wait that long to see your results.\n",
    "\n",
    "Testing your algorithm by using a single batch and training until overfitting \n",
    "is a great way of making sure that your model and optimizer are working the way they should!\n",
    "\n",
    "___\n",
    "\n",
    "### Part 0\n",
    "Watch Tutorial Video\n",
    "\n",
    "[https://youtu.be/0P-YctShbwc](https://youtu.be/0P-YctShbwc)\n",
    "\n",
    "**TODO:**\n",
    "* Watch video\n",
    "\n",
    "**DONE:**\n",
    "\n",
    "___\n",
    "\n",
    "### Part 1\n",
    "Your notebook should contain the boilerplate code. See below.\n",
    "\n",
    "**TODO:**\n",
    "\n",
    "* Replicate boilerplate from the video\n",
    "\n",
    "**DONE:**\n",
    "\n",
    "___\n",
    "\n",
    "### Part 2\n",
    "Your notebook should extend the boilerplate code by adding a testing loop.\n",
    "\n",
    "**TODO:**\n",
    "\n",
    "* Add a testing (validation) loop\n",
    "\n",
    "**DONE:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "QClXc9i7VRyA",
    "outputId": "d9282dca-0dc9-49c0-82e7-412861ccff78",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.16.5)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.3.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (4.3.0)\n",
      "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.1.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.16.5)\n",
      "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision) (0.46)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.28.1)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch \n",
    "!pip3 install torchvision\n",
    "!pip3 install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OU80yuvqVXwk",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms, utils, datasets\n",
    "from tqdm import tqdm\n",
    " \n",
    "assert torch.cuda.is_available() # You need to request a GPU from Runtime > Change Runtime Type\n",
    "\n",
    "# Write the boilerplate code from the video here\n",
    "\n",
    "# Create a dataset class that extends the torch.utils.data Dataset class here\n",
    "\n",
    "# Extend the torch.Module class to create your own neural network\n",
    "\n",
    "# Instantiate the train and validation sets\n",
    "\n",
    "# Instantiate your data loaders\n",
    "\n",
    "# Instantiate your model and loss and optimizer functions\n",
    "\n",
    "# Run your training / validation loops\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275
    },
    "colab_type": "code",
    "id": "FcshlrpvBYXg",
    "outputId": "3a1d7af9-d63f-44b7-fdd2-c0f880c23fb7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to /tmp/fashionmnist/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26427392it [00:02, 10313882.85it/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/fashionmnist/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to /tmp/fashionmnist/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32768it [00:00, 71979.91it/s]                            \n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/fashionmnist/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to /tmp/fashionmnist/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4423680it [00:01, 3059802.81it/s]                            \n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/fashionmnist/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to /tmp/fashionmnist/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8192it [00:00, 23949.76it/s]            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/fashionmnist/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ds = datasets.FashionMNIST('/tmp/fashionmnist', train = True,\n",
    "                                           transform=transforms.ToTensor(),\n",
    "                                           download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "colab_type": "code",
    "id": "rtvvpo46ef14",
    "outputId": "30c04b25-ae3b-4ad5-fd34-0938e537cd88"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss:1.989900: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4000/4000 [01:13<00:00, 54.28it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEKCAYAAAAB0GKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xd4VNX2//H3SqMGCB1TCFUISA0d\nKYI0FVTsBctX8XJFRcH+s9yr3mtFsWJv1y4WLCAovRN67yUJoUMIPWX9/jgnZEASJpCZSVmv55kn\nk9NmZVI+2Xufs4+oKsYYY8yZBAW6AGOMMUWDBYYxxhivWGAYY4zxigWGMcYYr1hgGGOM8YoFhjHG\nGK9YYBhjjPGKBYYxxhivWGAYY4zxSkigCyhIVatW1djY2ECXYYwxRcaCBQt2q2o1b7YtVoERGxtL\nQkJCoMswxpgiQ0S2eLutdUkZY4zxigWGMcYYr1hgGGOM8UqxGsMwxpjcpKenk5SUxNGjRwNdSkCU\nLl2aqKgoQkNDz/oYFhjGmBIhKSmJ8PBwYmNjEZFAl+NXqsqePXtISkqiTp06Z30c65IyxpQIR48e\npUqVKiUuLABEhCpVqpxz68oCwxhTYpTEsMhWEF+7BQbwxl/rWJ6cGugyjDGmUCvxgbH/8HG+mreV\nq0fP5o8V2wNdjjGmmNq/fz9vv/12vvfr168f+/fv90FF+VfiA6NS2TB+GtqJhjXD+cf/FjB66gZU\nNdBlGWOKmdwCIyMjI8/9fv/9dypVquSrsvKlxAcGQPXw0nwzuD39LqjF8+NW8+D3SzmekRXosowx\nxcgjjzzChg0baNGiBW3atOHCCy+kf//+xMXFAXD55ZfTunVrmjRpwnvvvXdiv9jYWHbv3s3mzZtp\n3Lgxd955J02aNKFXr14cOXLEr1+DnVbrKh0azJvXt6R+tfKM+msdW/ccZvTNralcLizQpRljCti/\nflnBym0HCvSYcedV4KnLmuS6/vnnn2f58uUsXryYKVOmcMkll7B8+fITp7l+9NFHVK5cmSNHjtCm\nTRsGDhxIlSpVTjrGunXr+Oqrr3j//fe55pprGDNmDDfddFOBfh15sRaGBxHh/osbMuq6FixO2s/l\nb81k/c60QJdljCmG2rZte9I1Ea+//jrNmzenffv2JCYmsm7dur/tU6dOHVq0aAFA69at2bx5s7/K\nBayF4Ti4C8pVBfe0swEtIomuXJbBny3girdn8dYNrejS0KvZf40xRUBeLQF/KVeu3InnU6ZM4c8/\n/2T27NmULVuWbt26nfaaiVKlSp14Hhwc7PcuKWthZGXC2+3gjVYw/lHYOAUyjtMqJoKfh3YislIZ\nbvtkPp/N3hzgQo0xRVl4eDhpaafvsUhNTSUiIoKyZcuyevVq5syZ4+fqvGMtjKwM6P4YrP0D5n8I\nc96GsHCofxGRDfswZlB37h2bxJM/r2DDzoM8cWkcIcGWs8aY/KlSpQqdOnWiadOmlClThho1apxY\n16dPH0aPHk3jxo05//zzad++fQArzZ0Up1NI4+Pj9ZxuoHT8EGyaBmvHOwGSlgIIGhnPVFrxwsZY\nqtVvzZs3tqJC6bOfwMsY43+rVq2icePGgS4joE73HojIAlWN92Z/a2F4CisH5/d1HqqwfSms/QNZ\nO55uye/SrRSkbK3MlFfa0rb3DdRs3gtCywS6amOM8QsLjNyIQK3mzqPrQ5C2A9ZNIGzRWHomTqbs\nr+PJHFea4HrdoGFvaNAbKkYGumpjjPEZCwxvhdeAVjdTpdXNJO7cx7OffkrD1FlcuXUZFdaOd7ap\neQE07AMNekFkawgKDmzNxhhTgHw2eisi0SIyWURWisgKEbnvNNsMEJGlIrJYRBJEpLPHultEZJ37\nuMVXdZ6N6OoRPH7vUOY2ephm+1/k+bqfkn7R085g+fRX4MOL4cW68N2tsOh/cCAl0CUbY8w582UL\nIwMYrqoLRSQcWCAiE1V1pcc2fwFjVVVFpBnwLdBIRCoDTwHxgLr7jlXVfT6sN1/KlQrh7Rtb8cak\n9YycuJbZB9rw7s1DqBl62Dk1d/1fsP5PWPGjs0ONplC/B9TvCdHtIcSuIDfGFC0+CwxVTQFS3Odp\nIrIKiARWemxz0GOXcjjhANAbmKiqewFEZCLQB/jKV/WeDRHh3h4NaFQznPu/Wcxlb85g9E2tad30\nSmh6pTNwvmOFExzr/4TZb8PMURBaDup2dQKkXg+ofPZ3wDLGGH/xywUFIhILtATmnmbdFSKyGvgN\nuN1dHAkkemyW5C4rlHo1qcmPd3eibFgw1783h28T3NJFoGZT6DwMbv0VHt4E130Fza9zguS34fB6\nC3ijNfz+EKydAMcPB/aLMcb41a233sr3339faI6TF58PeotIeWAMMExV/zbbl6r+CPwoIl2AZ4Ce\n+Tz+YGAwQExMzLkXfJYa1gjn57s7MfTLRTz0/VJWbjvA/7uk8ckX+ZUKh0b9nIcq7N2Y0/pY+BnM\nexeCS0Htjk7XVf2eUO38E1OWGGNMIPm0hSEioThh8YWq/pDXtqo6DagrIlWBZCDaY3WUu+x0+72n\nqvGqGl+tWmDne6pUNoxPbmvD7Z3q8MmszQz6aB77Dh0//cYiUKUetLsLbvwOHt4MN/8Ibe90Lhic\n8LgzZcnIOPhxCCz91jm11xhTpH322Wc0a9aM5s2bc/PNNwMwbdo0OnbsSN26dU9qJbz00ku0adOG\nZs2a8dRTT+V5DE9PPPEEt956K5mZmQVau89aGOLcQPZDYJWqjsxlm/rABnfQuxVQCtgD/AH8R0Qi\n3E17AY/6qtaCFBIcxJOXxdG4VjiP/7ic/m/N4P1B8TSqWSHvHUNLQ72LnEfv52B/ImyYBBsnO1ee\nL/nS2a56E6jXHep2h9odnIsNjTH5M+4R2L6sYI9Z8wLo+3yem6xYsYJnn32WWbNmUbVqVfbu3csD\nDzxASkoKM2bMYPXq1fTv35+rrrqKCRMmsG7dOubNm4eq0r9/f6ZNm0aVKlX+dgxPDz74IGlpaXz8\n8ccFfg9zX3ZJdQJuBpaJyGJ32WNADICqjgYGAoNEJB04Alyrzlwle0XkGWC+u9+/swfAi4qr46Op\nX708d32+gCvemsULVzWjf/PzvD9ApWhofYvzyMqC7Utgw2TnDKx578PsNyE4DKLbQd1uTojUamHX\nfhhTiE2aNImrr76aqlWrAlC5cmXAuXlSUFAQcXFx7Njh9CRMmDCBCRMm0LJlSwAOHjzIunXrWLJk\nyWmPAfDMM8/Qrl27k27AVJB8eZbUDCDPeFPVF4AXcln3EfCRD0rzm5YxEfx6T2f++cVC7v1qEcuS\n9vNwn0b5n7wwKAjOa+k8LnzAGRjfOttpfWyYApOecR6lK0GdLs4ZWLFdoGoDG/8w5nTO0BLwN89p\ny7Pn91NVHn30Ue66666Ttn3jjTdyPU6bNm1YsGABe/fuPSlICopNu+pj1SuU5ss723NLh9q8P30T\nN384jz0Hj53bQcPKOqfk9noWhsyAEetg4IfQ6FJIXuCcffVWG3ilEYy50xlQ37e5QL4eY8zZu+ii\ni/juu+/Ys2cPwN+6kzz17t2bjz76iIMHnasPkpOT2blzZ57H6NOnD4888giXXHJJrlOpnwubGsQP\nwkKC+NeAplwQVYnHf1zGZW/MYPTNrWkWVUA3di9fHS64ynlkn321aRpsnu60QpZ962xXMcZpgdS5\nEGIvtLmvjPGzJk2a8Pjjj9O1a1eCg4NPdDedTq9evVi1ahUdOnQAoHz58vzvf/877TE++eSTE/td\nffXVpKWl0b9/f37//XfKlCm4CVJtenM/W56cyl2fL2DXwWM8O6Ap17SJPvNO50IVdq1xA2QabJoO\nR/c76yrXcwOkixMg5e2ugqb4sunNbXrzIqdpZEV+uacz93y1kIfGLGVJ0n6euqwJYSE+6h0UgeqN\nnEe7wc4A+o7lOS2QZd/Dgo+dbavHOcFRpwvEdoIyEXkf2xhTolhgBEDlcmF8eltbXpqwhnenbmRl\nygFG39SaGhVK+/7Fg4KgVjPn0XEoZGZAyhLYNNUJkOwLCBFnm+wAiWkPpSv6vj5jTKFlXVIB9tvS\nFB78fgllw0J456ZWtIkt+DMb8iXjuDNwnt0CSZwLmcdBgqBmM4jtDLU7OdeAWAvEFCGrVq2iUaNG\nBX5tQlGhqqxevfqcuqQsMAqBtTvSuOvzBSTuPcwTl8YxqEPtwvNDnX4EkubD5pmweYbzPPMYIM4M\nvLGd3ADpBOWqBLpaY3K1adMmwsPDqVKlSuH5/fITVWXPnj2kpaVRp87Jk51aYBRBqUfSeeCbxfy1\neidXtIzkuSuaUjasEPYYph91WiBb3ABJnAcZR5x11RrnBEhsZ+fsLWMKifT0dJKSkjh69GigSwmI\n0qVLExUVRWho6EnLLTCKqKws5c3J63n1z7U0qF6et29sTf3q5QNdVt4yjsO2RbBlhtMKSZwLx91Z\n66s2zAmP2p2gQq3A1mqM+RsLjCJuxrrd3Pv1Io6mZ/L8wHxOKRJo2YPoW2Y4LZCtc+CYO0lx5bpu\n91VHiOkAEbF2JboxAWaBUQykpB5h6JeLWLBlH7d0qM1jlzSmVEgRnCcqKxO2L3VaH1tmwpZZOdeB\nlK/pnH0V08H5WKMpBBfCbjhjijELjGIiPTOLF8at5oMZm2geXYm3bmhJVETZQJd1brKyYNdqZy6s\nrXOcR+pWZ11YeYhqkxMgUfE2G68xPmaBUcyMX57Cg98tJThYePXaFnQ/v5gNJqcm5YTH1jnOhYUo\nSDDUap4TIDHtbSDdmAJmgVEMbd59iCFfLGRVygGGdq/P/Rc3JDiomPb/H9nvnL6b3QpJXgAZ7pkt\nlet5BEgH5yZUNg5izFmzwCimjqZn8tTPK/gmIZGO9aow6rqWVAsvdeYdi7qMY85A+olurNlwZJ+z\nrmxVj3GQDs7V6cGheR/PGHOCBUYx921CIk/8tJyKZUJ584ZWtK0T4KvD/S0rC/asOzlAsqdvDykD\nka2csZDodhDdFspVDWi5xhRmFhglwKqUA/zzi4Vs3XuYh/ucz50X1i1xV6+e5ECKExyJ8yBpntMi\nycpw1lWumxMeUW2hemO7M6ExLguMEiLtaDoPj1nK78u20yuuBi9d3ZyKZaw7BnCmNNm2yAmQ7BA5\ntMtZFxYOUa1zQiQyHsoU0L1JjCliLDBKEFXl45mb+c/vq6hZsTRvXN+SljE2KeDfqMK+TTkBkjgP\ndq4AzQIEqjVywiO6rRMkVerbYLopESwwSqBFW/dxz1eL2J56lIf6nM8dnesSVFzPoioox9KcM7AS\n5ztTmiTNg6OpzroyEU73VXaIRLa2a0JMsVQoAkNEooHPgBqAAu+p6qhTtrkReBgQIA0YoqpL3HWb\n3WWZQIY3X1BJDgxwJjB8+PuljF+xne7nV+OVa1pQuVxYoMsqOrIH0xPn5rRCdq9x1kkw1Gzqhojb\nlVUpxlohpsgrLIFRC6ilqgtFJBxYAFyuqis9tukIrFLVfSLSF3haVdu56zYD8aq629vXLOmBAU4X\n1f/mbOGZX1cRUS6UUde1pH1dm3b8rB3e67ZC3BBJXpAzuWL5GjkD6dHtnIsMQ/1wEyxjClChCIy/\nvZDIz8Cbqjoxl/URwHJVjXQ/34wFxllbsS2Ve75cxOY9h7ivR0OGXlS/+F7o509ZmbBz5cmtkH2b\nnHXBYU5oRLWF6DbOqb0VIq0VYgq1QhcYIhILTAOaquqBXLYZATRS1TvczzcB+3C6s95V1ffO9DoW\nGCc7eCyDJ35azo+LkulQtwqjrmtBdX/cBrakObjTuTI9ca4zHrJtYc6V6eG1nDmxoto6AXJeCwgt\nE9h6jfFQqAJDRMoDU4HnVPWHXLbpDrwNdFbVPe6ySFVNFpHqwETgHlWddpp9BwODAWJiYlpv2bLF\nR19J0aSqfL8giSd/XkHZsGBGXtuCrg2rBbqs4i0zHbYvg6QEJ0iS5ue0QoJCnFl5o9wWSHQbiKhj\nrRATMIUmMEQkFPgV+ENVR+ayTTPgR6Cvqq7NZZungYOq+nJer2ctjNyt25HG0C8XsWZHGkO61eOB\nixsSGhwU6LJKjkO73QCZ5wRI8sKcsZCyVdwAiXdbIa2gdIXA1mtKjEIRGOJcdvwpsFdVh+WyTQww\nCRikqrM8lpcDglQ1zX0+Efi3qo7P6zUtMPJ2ND2Tf/2ykq/mbaVVTCVev74YTJdeVGVlOtO8Z7dA\nkhKczwEQ52p0z66sqg0hyALeFLzCEhidgenAMiDLXfwYEAOgqqNF5ANgIJDdj5ShqvEiUhen1QEQ\nAnypqs+d6TUtMLzzy5JtPPrDMoKDhJeuakavJjUDXZIBZ5be5AUnd2Vl32yqVAXnWpDsrqyoeChb\nwuYQMz5RKAIjECwwvLdlzyGGfrmIZcmp3Noxlkf7NSqad/QrzlRhz4acbqyk+bAj++p0nKneo9vm\ndGVVb2J3LDT5ZoFhvHIsI5MXxq3ho5mbaFyrAm9c34L61cMDXZbJy7GDkLLYPSvLDZFDO511oWXh\nvJY5ARLVBsKt9WjyZoFh8mXS6h2M+G4ph49n8MSlcdzQNqZkz3xblKjC/q054yBJ892ZetOd9RVj\nTg6QWs0gpATcQ8V4zQLD5NvOA0cZ/t0Spq/bTe8mNXj+ymZE2LQiRVP6Udi+9OQB9dREZ11wGNRs\ndnJXVsVoO623BLPAMGclK0v5aOYmXhi/mirlSjHy2uZ0rGc3HyoWDqRAcoI71XuCM/V7xhFnXfka\nHoPpbZxurTA7e66ksMAw52R5cir3fr2ITbsPMaRrPe63azaKn8x0ZwD9RCtkPuzd6KzznGjRLi4s\n9iwwzDk7fDyDZ35dyVfzEmkeVZFR17UktqpN712s5XlxYdWc03mj2zoXF5YqH9h6TYGwwDAFZtyy\nFB75YRkZmVn8e0BTrmwVaQPiJUVWJuxc5QaI2521Z52zToKc03izx0Gi29pNp4ooCwxToLbtP8L9\n3yxm7qa99G9+Hs9e0ZQKpe1WsCXS4b1Oy+PEtSEL4Jh706nSlU6eIyuyNZSuGNh6zRlZYJgCl5ml\nvDNlPa/+uY5aFUsz6roWtK5tVxqXeFlZsHttToAkznenOFFO3Po2uxsrqg1UPd+mOClkLDCMzyzc\nuo/7vl5E8r4j3NejIXd3r0eIDYgbT0dTc6Y4SZx3+ilOsgMksrVNcRJgFhjGp9KOpvPkzyv4cVEy\n8bUjePXaFkRXttMwTS5UYc/6nLOxEufDTo8pTqo0yOnGimoD1eMgyKap8RcLDOMXPy1K5omflpOl\nylP9m3B16ygbEDfeOXbQudHUiSlO5sHhPc66sPLOtSDZrZCoNlDOrgfyFQsM4zdJ+w4z/NslzN20\nl95NavDfK5tR2a4QN/ml6txkyrMba/sy0ExnfUSdkwOkRhMIthMvCoIFhvGrzCzlg+kbeXnCGiqV\nDePFq5rR/fzqgS7LFHXHDzsTLSZ6zNZ7cIezLqQMRLbymCerLYTXCGy9RZQFhgmIldsOcP83i1mz\nI42b29fmsX6NKRNmfdGmgKg6c2J5ztTrOdFiRCxEt8t5VG9sYyFesMAwAXM0PZOX/1jDBzM2Ubda\nOV67tgXNoioFuixTXKUfdUIjaR4kzoWtc3Omew8Ld1ogMe2d7qzIeLv17WlYYJiAm7V+N8O/W8Ku\ntGPc16MBQ7rZ6bfGD1Rh32anGytxjvNxxwpAc65Oj27rtEBi2kGl2iX+6nQLDFMopB5O54mflzN2\nyTZaxVTi1WtbULuKzUdl/OzoAWem3q1znVZIUgIcT3PWla+REyDR7Uvk/UIsMEyh8vPiZP7fT8vJ\nylKevCyOa+Kj7fRbEzhZmbBzpRMeiW5X1r7NzrrgUjmn9Ma0dwbTy1cLaLm+ZoFhCp1t+48w/Nsl\nzN64h4vjavD8lRdQpXzJ+k/OFGJp23PCI3EubFucM5heua7T+shuiVRrVKymN7HAMIVS9g2aXhy/\nhgplQvnvlRdwcZydCmkKofSjzim9W+fkBMnh3c66UhWdq9Kj2+UMphfhqd4LRWCISDTwGVADZyay\n91R11Cnb3Ag8DAiQBgxR1SXuuj7AKCAY+EBVnz/Ta1pgFA2rtx/g/m+WsCrlAANbRfHkZXFULGMX\nYZlCTNW5wVR2CyRxnjP1e/Zgeo2m7kC62xIpQre9LSyBUQuopaoLRSQcWABcrqorPbbpCKxS1X0i\n0hd4WlXbiUgwsBa4GEgC5gPXe+57OhYYRcfxjCzemLSOt6dsoHp4KV4Y2IwuDYt3X7EpZo7sd69M\n9xhMTz/krAuv5XZhtXeCpOYFEFI4Z0AoFIHxtxcS+Rl4U1Un5rI+AliuqpEi0gEnPHq76x4FUNX/\n5vUaFhhFz5LE/Qz/bgnrdx7khnYxPNavMeVLhQS6LGPyLzPDmVQxcV5OV1bqVmddSGnnLoUx7kWF\nUW2hXJXA1usqdIEhIrHANKCpqh7IZZsRQCNVvUNErgL6qOod7rqbgXaqOvQ0+w0GBgPExMS03rJl\ni2++COMzR9MzGTlxLe9P30hURBleuqo57esWjl8mY87JgW0nn42VsgSyMpx1VRrkjIPEtHc+D8Bg\neqEKDBEpD0wFnlPVH3LZpjvwNtBZVffkJzA8WQujaJu/eS8jvlvC1r2Hua1jHR7qcz6lQ21qB1OM\npB9x7ljoGSJH9jrrSldyu7HcrqzIVhDm++uW8hMYPm37i0goMAb4Io+waAZ8APRVVXd+Y5KBaI/N\notxlphhrE1uZcfddyPPjVvPRzE1MWbOTl69pTquYiECXZkzBCC0DsZ2cB+TcKyR7HGTrXFg3wVkn\nwc7YR/ZV6dHtoGJU4GrHt4PeAnwK7FXVYblsEwNMAgap6iyP5SE4g949cIJiPnCDqq7I6zWthVF8\nzFy/m4e+X0pK6hHu6lqPYT0bUCrEWhumBDi81x1Md8dBkhIg44izrkKkxwSLbZ1AOcdp3gtFl5SI\ndAamA8sA99ZaPAbEAKjqaBH5ABgIZA88ZGQXLiL9gNdwTqv9SFWfO9NrWmAUL2lH03n211V8k5DI\n+TXCeeWa5jSNrBjosozxr8x0594gJy4snAcHkpx1oWVzbnnb/f+d1RhIoQiMQLDAKJ4mrd7BI2OW\nsffQcYZeVJ+7u9cn1CYyNCVZatLJ4yDHD8PQeWd1KAsMU+zsP3ycp8eu4KfF22gaWYFXrm7B+TXD\nA12WMYVDZgYEn92QdH4Cw/5NM0VCpbJhvHZdS0bf1IqU/Ue59I3pvPHXOtIzs868szHF3VmGRX5Z\nYJgipU/TWky4vwu9m9TklYlrGfDmTFZsSw10WcaUCBYYpsipUr4Ub97QitE3tWZn2jEGvDmTkRPW\ncDzDWhvG+JIFhimy+jStycT7u3BZ8/N4fdJ6LntjBkuT9ge6LGOKLQsMU6RFlAvj1Wtb8OEt8ew/\ncpwr3p7FC+NXczQ9M9ClGVPsWGCYYqFH4xpMuL8rV7aM5J0pG7j0jRks3Lov0GUZU6xYYJhio2KZ\nUF66ujmf3NaGw8cyuOqdWTz320prbRhTQCwwTLHT7fzq/HF/F65rG8P70zfRd9R05m/eG+iyjCny\nLDBMsRReOpT/XHEBX9zRjvTMLK55dzZPj13B4eMZgS7NmCLLq8AQkXoiUsp93k1E7hWRSr4tzZhz\n16l+Vf4Y1oVB7WvzyazN9H5tGrPW7w50WcYUSd62MMYAmSJSH3gPZ+rxL31WlTEFqFypEP41oCnf\nDG5PsAg3fDCXh79fSurh9ECXZkyR4m1gZKlqBnAF8IaqPgjU8l1ZxhS8dnWrMO6+LtzVtS7fL0yi\n56tTGbcsJdBlGVNkeBsY6SJyPXAL8Ku77NwmYTcmAMqEBfNo38b8fHcnqpUvxZAvFnLX5wnsPHA0\n0KUZU+h5Gxi3AR1wbrO6SUTqAJ/7rixjfKtpZEV+HtqJh/s0YsqaXfQYOZWv522lOM3ebExBy/f0\n5iISAUSr6lLflHT2bHpzczY27T7EI2OWMnfTXjrUrcJ/r7yA2Kq+v5eyMYVBgU9vLiJTRKSCiFQG\nFgLvi8jIcynSmMKiTtVyfHVne/575QUsT06l92vTGD11Axk2dboxJ/G2S6qiqh4ArgQ+U9V2QE/f\nlWWMfwUFCde3jeHP4V3p2rAaz49bzYC3ZrI82aZONyabt4ERIiK1gGvIGfQ2ptipUaE0797cmrdv\nbMWOA8cY8NZMnh9nkxkaA94Hxr+BP4ANqjpfROoC63xXljGBIyL0u6AWfz7QhYGtIhk9dQO9X5vG\njHV2wZ8p2bwKDFX9TlWbqeoQ9/ONqjowr31EJFpEJovIShFZISL3nWabRiIyW0SOiciIU9ZtFpFl\nIrJYRGwk2/hdpbJhvHhVc768ox0C3PThXO7/ZjF7Dh4LdGnGBIS3g95RIvKjiOx0H2NEJOoMu2UA\nw1U1DmgP3C0icadssxe4F3g5l2N0V9UW3o7gG+MLHetXZfywLtxzUX1+XbqNHiOn8m1Cop2Ca0oc\nb7ukPgbGAue5j1/cZblS1RRVXeg+TwNWAZGnbLNTVecDNkeDKdRKhwYzvNf5/HbvhdSvVp6Hvl/K\n9e/PYeOug4EuzRi/8TYwqqnqx6qa4T4+Aap5+yIiEgu0BObmozYFJojIAhEZnI/9jPGZhjXC+fau\nDjx3RVNWbDtAn1HTef2vdXY/cVMieBsYe0TkJhEJdh83AXu82VFEyuNMXjjMPTXXW51VtRXQF6c7\nq0suxx8sIgkikrBr1658HN6YsxMUJNzYrjZ/PdCVi+NqMHLiWvq9bvfcMMWft4FxO84ptduBFOAq\n4NYz7SQioThh8YWq/pCfwlQ12f24E/gRaJvLdu+paryqxler5nWjx5hzVr1Cad66oRUf39qGI8cz\nuXr0bB79wWbBNcWXt2dJbVHV/qpaTVWrq+rlwJnOkhLgQ2CVqubrqnARKSci4dnPgV7A8vwcwxh/\n6d6oOhMf6MKdF9bhm/mJ9Bg5lbFLttmguCl28j2X1IkdRbaqakwe6zsD04FlQHYH72NADICqjhaR\nmkACUMHd5iAQB1TFaVUAhABfqupzZ6rJ5pIygbY8OZVHf1jGsuRUujasxrOXNyW6ctlAl2VMrvIz\nl9S5BEaiqkaf1c4+YoFhCoP8ze6QAAAW2ElEQVTMLOXTWZt5ecIaslR54OKG3N6pDiHBdkdkU/gU\n+OSDubD2tjGnERwk3N65Dn8+0JXO9avxn99X0//NmSxJ3B/o0ow5J3kGhoikiciB0zzScK7HMMbk\n4rxKZXh/UGtG39SKPYeOccXbM3l67AoOHssIdGnGnJWQvFaqari/CjGmOBIR+jStRcf6VXn5jzV8\nOnszf6zYzr/6N6FXk5qBLs+YfLFOVWP8oELpUP49oCljhnSkQulQBn++gMGfJZC8/0igSzPGaxYY\nxvhRq5gIfr23Mw/3acS0dbvo+cpURk/dQLrdrMkUARYYxvhZaHAQQ7rVcwbFG1Tl+XGr6TdqOnM3\nejV5gjEBY4FhTIBERZTl/UHxfDAoniPpmVz73hwe+HYxu236dFNIWWAYE2A942ow8f6u3N29Hr8s\n2cZFL0/h8zlbyMyyM9dN4WKBYUwhUCYsmAd7N2LcfV1oGlmRJ35azpVvz2RZkt1T3BQeFhjGFCL1\nq5fnizvaMeq6FiTvP0r/t2bw5M/LST1iExqawLPAMKaQEREGtIhk0oiu3NIhlv/N2UKPV6by06Jk\nm9DQBJQFhjGFVIXSoTzdvwljh3YmMqIMw75ZzPXvz2H9zrRAl2ZKKAsMYwq5ppEV+XFIR567oimr\nUtLoO2o6L4xfzeHjNsWI8S8LDGOKgBN3+RvelQEtInlnygYuHjmNP1Zst24q4zcWGMYUIVXLl+Ll\nq5vz7V0dKF8qhLs+X8CtH89n0+5DgS7NlAAWGMYUQW3rVObXezvzxKVxLNiyj96vTuPlP9Zw5Hhm\noEszxZgFhjFFVGhwEP/XuQ6Thnflkma1eHPyenqOnMr45SnWTWV8wgLDmCKueoXSvHptC769qwPh\npUP4x/8WMuijeWzcdTDQpZlixgLDmGKibZ3K/HpPZ568NI7FW/fT+7VpvGhnU5kCZIFhTDESEhzE\n7Z3r8NeIrlzW/DzenrKBnq9MZdwy66Yy584Cw5hiqHp4aUZe04Lv/tGBCmVCGfKF0021wbqpzDnw\nWWCISLSITBaRlSKyQkTuO802jURktogcE5ERp6zrIyJrRGS9iDziqzqNKc7axDrdVE9fFsfixP30\neW0az49bzSG7r7g5C75sYWQAw1U1DmgP3C0icadssxe4F3jZc6GIBANvAX2BOOD60+xrjPFCSHAQ\nt3aqw6Th3RjQIpLRUzfQc+RUfltq3VQmf3wWGKqaoqoL3edpwCog8pRtdqrqfODUqTjbAutVdaOq\nHge+Bgb4qlZjSoJq4c5Ff2OGdCCibBh3f7mQmz6cy/qd1k1lvOOXMQwRiQVaAnO93CUSSPT4PIlT\nwsbj2INFJEFEEnbt2nUuZRpTIrSuXZlf7unMvwc0YVlSKn1HTeO/41ZZN5U5I58HhoiUB8YAw1T1\nQEEfX1XfU9V4VY2vVq1aQR/emGIpOEgY1CGWSSO6cUXLSN6dupEer0zllyXbrJvK5MqngSEioThh\n8YWq/pCPXZOBaI/Po9xlxpgCVLV8KV68qjljhnSkSvkw7vlqETd+MJd1O2wKdfN3vjxLSoAPgVWq\nOjKfu88HGohIHREJA64DxhZ0jcYYR+vaEYwd2plnLm/K8uRU+o6azn9+X8VB66YyHsRXzU8R6QxM\nB5YBWe7ix4AYAFUdLSI1gQSggrvNQSBOVQ+ISD/gNSAY+EhVnzvTa8bHx2tCQkKBfy3GlCR7Dh7j\nxfFr+CYhkRoVSvH4JXFc1qwWzv+AprgRkQWqGu/VtsWpv9ICw5iCs2jrPp78eQXLklPpULcK/xrQ\nhIY1wgNdlilg+QkMu9LbGHNaLWMi+OnuTjx3RVNWphyg36jpPPvrSg4cPfUseFNSWGAYY3IV7N7p\nb/KIblwdH8WHMzdx0ctT+DYhkays4tM7YbxjgWGMOaPK5cL475XNGHt3Z2Iql+Wh75dyxTuzWLR1\nX6BLM35kgWGM8doFURUZM6Qjr17bnJT9R7ji7VmM+G4JO9OOBro04wcWGMaYfBERrmgZxaQR3fhH\n13r8vDiZi16eynvTNnA8I+vMBzBFlgWGMeaslC8VwiN9GzHh/q60rVOZ//y+mj6vTWPKmp2BLs34\niAWGMeac1Klajo9ubcPHt7ZBgVs/ns8dn85n8+5DgS7NFDALDGNMgejeqDp/DOvCo30bMXvDHnq9\nOo0Xxtu9N4oTCwxjTIEJCwnirq71mDyiG5c2r8U7UzZw0StT+GlRsk1qWAxYYBhjClz1Cs4tYscM\n6Uj18NIM+2YxV42ezfLk1ECXZs6BBYYxxmda147g57s78cLAC9i8+xCXvTmDR39Yyp6DxwJdmjkL\nFhjGGJ8KChKubRPDpBHduL1THb5LSKLby1P4eOYm0jPtNNyixALDGOMXFcuE8sSlcYy770KaR1Xi\nX7+s5JLXpzNz/e5Al2a8ZIFhjPGrBjXC+fz/2vLuza05fDyTGz+Yy+DPEtiyx07DLewsMIwxfici\n9G5Skz8f6MqIXg2ZsX43F4907i2eZrPhFloWGMaYgCkdGszQixqcOA333akb6f7yVL6Zv5VMmw23\n0LHAMMYEXA33NNyf7u5ETOUyPDxmGf3fnMG8TXsDXZrxYIFhjCk0WkRXYsyQjoy6rgV7Dx3nmndn\nc/cXC0ncezjQpRksMIwxhYyIMKBFJJOGd2NYzwb8tXoHPUZO5eU/1tg0IwFmgWGMKZTKhAUzrGdD\nJg3vRt+mNXlz8nouemUKYxYk2d3+AsRngSEi0SIyWURWisgKEbnvNNuIiLwuIutFZKmItPJYlyki\ni93HWF/VaYwp3M6rVIZR17VkzJCO1KxQmuHfLeGKd2axYIvd7c/ffNnCyACGq2oc0B64W0TiTtmm\nL9DAfQwG3vFYd0RVW7iP/j6s0xhTBLSuHcGP/+zEK1c7d/sb+M4s7vt6Edv2Hwl0aSWGzwJDVVNU\ndaH7PA1YBUSestkA4DN1zAEqiUgtX9VkjCnagoKEga2jmDyiG0O712fc8u1c9MoUXvtzLUeOZwa6\nvGLPL2MYIhILtATmnrIqEkj0+DyJnFApLSIJIjJHRC73eZHGmCKjXKkQRvQ+n78e6EqPRjV47c91\n9HhlCj8vtmnUfcnngSEi5YExwDBVPZCPXWurajxwA/CaiNTL5fiD3WBJ2LVrVwFUbIwpKqIrl+Wt\nG1vxzeD2RJQL476vnWnUlyTuD3RpxZJPA0NEQnHC4gtV/eE0myQD0R6fR7nLUNXsjxuBKTgtlL9R\n1fdUNV5V46tVq1aA1Rtjiop2daswdmhnXhh4AVv2HGLAWzN54NvFbE89GujSihVfniUlwIfAKlUd\nmctmY4FB7tlS7YFUVU0RkQgRKeUepyrQCVjpq1qNMUVfsDuN+uQR3bira11+XZJC95en8OrEtRw+\nbtdvFATxVX+fiHQGpgPLgOxJ7x8DYgBUdbQbKm8CfYDDwG2qmiAiHYF33f2CgNdU9cMzvWZ8fLwm\nJCQU+NdijCl6Evce5vnxq/ltaQo1KpTiwd6NuLJlJEFBEujSChURWeB2/5952+I0QGSBYYw5VcLm\nvTzz60qWJKXSNLIC/++SONrXrRLosgqN/ASGXeltjCnW4mMr8+M/OznzUx08znXvzeGuzxPYvNvu\nv5FfFhjGmGIvKMiZn+qv4d0YfnFDpq/bzcWvTuXZX1eSesTuv+EtCwxjTIlRJiyYe3o0YMqIblzZ\nMooPZ26i20uT+XTWZru/uBcsMIwxJU71CqV54apm/HpPZxrVrMBTY1fQ57VpTFq9wy78y4MFhjGm\nxGpyXkW+vLMdHwyKRxVu/ySBQR/NY/X2/FxjXHJYYBhjSjQRoWdcDcYP68JTl8WxNCmVfqOm8+gP\ny9iVdizQ5RUqFhjGGAOEhQRxW6c6TH2wG7d2rMN3CYl0e2kyb01ez9F0m9gQLDCMMeYklcqG8eRl\ncUy4vwsd61flpT/W0OOVqYxdsq3Ej29YYBhjzGnUrVae9wfF8+Ud7ahYJpR7v1rElSX8xk0WGMYY\nk4eO9avyyz2defGqZiTvc27cdPeXC9m653CgS/M7mxrEGGO8dOhYBu9P38i7UzeSkZXFLR1iGXpR\nfSqVDQt0aWfNpgYxxhgfKFcqhGE9GzLlwZwL/7q+NIUPpm/kWEbxHxi3wDDGmHyq4V749/u9F9I8\nuhLP/raKi0dO4/dlKcV6YNwCwxhjzlLjWhX47Pa2fHp7W8qGBfPPLxYysBgPjFtgGGPMOerasBq/\n3XshLw5sRlL2wPgXC9myp3jNiGuD3sYYU4BOHRgf1CGWewrxwLgNehtjTIBkD4xPfbAbA1tF8XEx\nGhi3wDDGGB+oXqE0zw9sxu/3XUgLj4Hx35YW3YFxCwxjjPGhRjUr8OntbfnMHRi/+8vsgfG9gS4t\n3ywwjDHGD7r8bWB8Nv/8YkGRGhj3WWCISLSITBaRlSKyQkTuO802IiKvi8h6EVkqIq081t0iIuvc\nxy2+qtMYY/wlOEi4pk00Ux7sxv09GzJlzS56jpzKM7+uZP/h44Eu74x8dpaUiNQCaqnqQhEJBxYA\nl6vqSo9t+gH3AP2AdsAoVW0nIpWBBCAeUHff1qqa58nNdpaUMaYo2XngKCMnruXbhETKlwrh3h4N\nuLlDbUqFBPuthkJxlpSqpqjqQvd5GrAKiDxlswHAZ+qYA1Ryg6Y3MFFV97ohMRHo46tajTEmEDwH\nxlvGRPDsb6voOXIqvy4tnFOp+2UMQ0RigZbA3FNWRQKJHp8nuctyW26MMcWO58B4ubAQhn6ZPZV6\n4RoY93lgiEh5YAwwTFUL/Ea5IjJYRBJEJGHXrl0FfXhjjPGbEwPjVzVj235nYPwfny9g466DgS4N\n8HFgiEgoTlh8oao/nGaTZCDa4/Mod1luy/9GVd9T1XhVja9WrVrBFG6MMQESHCRcEx/N5BHdGH5x\nQ6av28XFr07jiZ+WB/we4748S0qAD4FVqjoyl83GAoPcs6XaA6mqmgL8AfQSkQgRiQB6ucuMMaZE\nKBsWwj09GjD1oe7c2C6Gr+ZtpdtLk3n9r3UcPp4RkJp8eZZUZ2A6sAzIchc/BsQAqOpoN1TexBnQ\nPgzcpqoJ7v63u9sDPKeqH5/pNe0sKWNMcbVx10Fe+mMN45Zvp1p4KR64uCFXt44iJPjc/u/Pz1lS\nNvmgMcYUIQu27OU/v69mwZZ91K9enkf6NKJH4+o4/3/nX6E4rdYYY0zBa127Mt//owOjb2pNVpZy\nx2cJXPveHI4c9/3EhiE+fwVjjDEFSkTo07QmPRpX5+v5iaxITqVMmO8v9rPAMMaYIio0OIib29f2\n2+tZl5QxxhivWGAYY4zxigWGMcYYr1hgGGOM8YoFhjHGGK9YYBhjjPGKBYYxxhivWGAYY4zxSrGa\nS0pEdgFbznL3qsDuAiynoFhd+WN15Y/VlT/Fsa7aqurVvSGKVWCcCxFJ8HYCLn+yuvLH6sofqyt/\nSnpd1iVljDHGKxYYxhhjvGKBkeO9QBeQC6srf6yu/LG68qdE12VjGMYYY7xiLQxjjDFeKfGBISJ9\nRGSNiKwXkUf8/NrRIjJZRFaKyAoRuc9d/rSIJIvIYvfRz2OfR91a14hIbx/WtllElrmvn32f9coi\nMlFE1rkfI9zlIiKvu3UtFZFWPqrpfI/3ZLGIHBCRYYF6v0TkIxHZKSLLPZbl+z0SkVvc7deJyC0+\nquslEVntvvaPIlLJXR4rIkc83rvRHvu0dn8G1ru1n909QPOuK9/fu4L+nc2lrm88atosIovd5X55\nv/L42xDYny9VLbEPIBjYANQFwoAlQJwfX78W0Mp9Hg6sBeKAp4ERp9k+zq2xFFDHrT3YR7VtBqqe\nsuxF4BH3+SPAC+7zfsA4QID2wFw/fe+2A7UD9X4BXYBWwPKzfY+AysBG92OE+zzCB3X1AkLc5y94\n1BXrud0px5nn1ipu7X19UFe+vne++J09XV2nrH8FeNKf71cefxsC+vNV0lsYbYH1qrpRVY8DXwMD\n/PXiqpqiqgvd52nAKiAyj10GAF+r6jFV3QSsx/ka/GUA8Kn7/FPgco/ln6ljDlBJRGr5uJYewAZV\nzetCTZ++X6o6Ddh7mtfMz3vUG5ioqntVdR8wEehT0HWp6gRVzXA/nQNE5XUMt7YKqjpHnb88n3l8\nLQVWVx5y+94V+O9sXnW5rYRrgK/yOkZBv195/G0I6M9XSQ+MSCDR4/Mk8v6D7TMiEgu0BOa6i4a6\nTcuPspud+LdeBSaIyAIRGewuq6GqKe7z7UCNANSV7TpO/iUO9PuVLb/vUSBqvB3nv9FsdURkkYhM\nFZEL3WWRbi3+qCs/3zt/v18XAjtUdZ3HMr++X6f8bQjoz1dJD4xCQUTKA2OAYap6AHgHqAe0AFJw\nmsT+1llVWwF9gbtFpIvnSve/qICcYiciYUB/4Dt3UWF4v/4mkO9RbkTkcSAD+MJdlALEqGpL4AHg\nSxGp4MeSCuX3zsP1nPyPiV/fr9P8bTghED9fJT0wkoFoj8+j3GV+IyKhOD8QX6jqDwCqukNVM1U1\nC3ifnG4Uv9Wrqsnux53Aj24NO7K7mtyPO/1dl6svsFBVd7g1Bvz98pDf98hvNYrIrcClwI3uHxvc\nLp897vMFOOMDDd0aPLutfFLXWXzv/Pl+hQBXAt941Ou39+t0fxsI8M9XSQ+M+UADEanj/td6HTDW\nXy/u9o9+CKxS1ZEeyz37/68Ass/eGAtcJyKlRKQO0ABnoK2g6yonIuHZz3EGTJe7r599lsUtwM8e\ndQ1yz9RoD6R6NJt94aT/+gL9fp0iv+/RH0AvEYlwu2N6ucsKlIj0AR4C+qvqYY/l1UQk2H1eF+c9\n2ujWdkBE2rs/p4M8vpaCrCu/3zt//s72BFar6omuJn+9X7n9bSDQP19nO1peXB44ZxesxflP4XE/\nv3ZnnCblUmCx++gHfA4sc5ePBWp57PO4W+sazvGslTzqqotz9skSYEX2+wJUAf4C1gF/ApXd5QK8\n5da1DIj34XtWDtgDVPRYFpD3Cye0UoB0nL7h/zub9whnTGG9+7jNR3Wtx+nLzv45G+1uO9D9Hi8G\nFgKXeRwnHucP+AbgTdwLfQu4rnx/7wr6d/Z0dbnLPwH+ccq2fnm/yP1vQ0B/vuxKb2OMMV4p6V1S\nxhhjvGSBYYwxxisWGMYYY7xigWGMMcYrFhjGGGO8YoFhzBmISKacPEtugc1qLM7sp8vPvKUxgRcS\n6AKMKQKOqGqLQBdhTKBZC8OYsyTOfRJeFOceCPNEpL67PFZEJrkT6v0lIjHu8hri3Itiifvo6B4q\nWETeF+e+BxNEpIy7/b3i3A9hqYh8HaAv05gTLDCMObMyp3RJXeuxLlVVL8C5svc1d9kbwKeq2gxn\nkr/X3eWvA1NVtTnO/RdWuMsbAG+pahNgP87VxODc76Cle5x/+OqLM8ZbdqW3MWcgIgdVtfxplm8G\nLlLVje5EcdtVtYqI7MaZ4iLdXZ6iqlVFZBcQparHPI4Ri3O/ggbu5w8Doar6rIiMBw4CPwE/qepB\nH3+pxuTJWhjGnBvN5Xl+HPN4nknO2OIlOPMDtQLmu7OnGhMwFhjGnJtrPT7Odp/PwplFFeBGYLr7\n/C9gCICIBItIxdwOKiJBQLSqTgYeBioCf2vlGONP9h+LMWdWRkQWe3w+XlWzT62NEJGlOK2E691l\n9wAfi8iDwC7gNnf5fcB7IvJ/OC2JITizpJ5OMPA/N1QEeF1V9xfYV2TMWbAxDGPOkjuGEa+quwNd\nizH+YF1SxhhjvGItDGOMMV6xFoYxxhivWGAYY4zxigWGMcYYr1hgGGOM8YoFhjHGGK9YYBhjjPHK\n/wdrLkRxQy3WkwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define the numbers for this particular dataset and this particular setup\n",
    "\n",
    "in_dim = 784    # because the dataset is 28x28 (=728) images with only one channel\n",
    "                # -- note that I put 728 because I will flatten out the images\n",
    "                # before putting them in\n",
    "\n",
    "out_dim = 10    # we want to classify each image as one of 10 things!\n",
    "\n",
    "num_epochs = 2000  # this is the number of times we want to run through \n",
    "                # the network on the training set\n",
    "  \n",
    "one_batch_size = 50  # this is the number of items that will be processed in one\n",
    "                     # run; the number of items that will influence a single \n",
    "                     # step down the gradient\n",
    "\n",
    "dataset_size = 100 # this is the size of the total datasets for the purpose of\n",
    "                   # trying to overfit\n",
    "  \n",
    "  \n",
    "  \n",
    "  \n",
    "class LinearNetwork(nn.Module):\n",
    "  '''Define the Linear Network to classify the FashionMNIST dataset'''\n",
    "  \n",
    "  def __init__(self, dataset):             # each network defined must contain\n",
    "                                           # an __init__() function and a forward()\n",
    "                                           # function.\n",
    "    super(LinearNetwork, self).__init__()  \n",
    "    x, y = dataset[0]\n",
    "    c, h, w = x.size()                     # c, h, w = channels, height, width\n",
    "                                           # The following line defines the architecture\n",
    "                                           # of this particular network\n",
    "    self.net = nn.Sequential(nn.Linear(in_dim, 500),\n",
    "                             nn.ReLU(),\n",
    "#                              nn.Linear(500,100),\n",
    "#                              nn.ReLU(),\n",
    "                             nn.Linear(500, out_dim)\n",
    "                            )  \n",
    "    \n",
    "  def forward(self, x):                    # the forward function serves to tell\n",
    "                                           # the network how to actually construct\n",
    "                                           # the layers of the net, and in which\n",
    "                                           # order and manner to backpropogate\n",
    "    n, c, h, w = x.size()\n",
    "    flattened = x.view(n, c * h * w)  \n",
    "    return self.net(flattened)\n",
    "  \n",
    "  \n",
    "  \n",
    "class Train_FashionMNISTProcessedDataset(Dataset):\n",
    "  '''Define the training Dataset'''\n",
    "  def __init__(self, root, train=True):    # note that train is True on the training set\n",
    "    \n",
    "    self.data = datasets.FashionMNIST(root, train = train,\n",
    "                                           transform=transforms.ToTensor(),\n",
    "                                           download=True)\n",
    "\n",
    "                            # each dataset must have a __getitem__\n",
    "                            # and a __len__ method\n",
    "  def __getitem__(self, i):             \n",
    "    x,y = self.data[i]\n",
    "    return x, y\n",
    "\n",
    "  def __len__(self):\n",
    "    return dataset_size # typically, I would put len(self.data) here, but I want\n",
    "                        # to overfit to fill the requirement of the assignment\n",
    "  \n",
    "  \n",
    "  \n",
    "  \n",
    "class Check_FashionMNISTProcessedDataset(Dataset):\n",
    "  '''Define the check Dataset (also called the testing dataset, but calling it \n",
    "     check adds for use of the variables 'c' and 't' for future reference)'''\n",
    "  def __init__(self, root, train=False):    # note that train is False on the validation set\n",
    "    \n",
    "    self.data = datasets.FashionMNIST(root, train = train,\n",
    "                                           transform=transforms.ToTensor(),\n",
    "                                           download=True)\n",
    "\n",
    "                            # each dataset must have a __getitem__\n",
    "                            # and a __len__ method\n",
    "  def __getitem__(self, i):             \n",
    "    x,y = self.data[i]\n",
    "    return x, y\n",
    "\n",
    "  def __len__(self):\n",
    "    return dataset_size # typically, I would put len(self.data) here, but I want\n",
    "                        # to overfit to fill the requirement of the assignment\n",
    "  \n",
    "    \n",
    "    \n",
    "  # With the classes established, I create instances of my training and checking\n",
    "  # datasets, along with the model (the network created above).  \n",
    "    \n",
    "train_dataset = Train_FashionMNISTProcessedDataset('/tmp/fashionmnist', train=True)\n",
    "check_dataset = Check_FashionMNISTProcessedDataset('/tmp/fashionmnist', train=False)\n",
    "model = LinearNetwork(train_dataset)\n",
    "model = model.cuda()   # we add model to the GPU here\n",
    "\n",
    "  # also establish the objective (or loss) function here, as well as the optimizer\n",
    "objective = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr = 1e-4)\n",
    "\n",
    "                       # the train loader and check loader allow for access to the\n",
    "                       # items in their respective dataset; they allow them to be\n",
    "                       # processed together one batch at a time.\n",
    "                                     \n",
    "train_loader = DataLoader(train_dataset,\n",
    "                         batch_size = one_batch_size,\n",
    "                         pin_memory = True)\n",
    "check_loader = DataLoader(check_dataset,\n",
    "                         batch_size = one_batch_size,\n",
    "                         pin_memory = True)\n",
    "\n",
    "  # these train_looses and check_losses arrays will fill up with the loss values\n",
    "train_losses = []\n",
    "check_losses = []\n",
    "\n",
    "\n",
    "# the tqdm shows the information as you train\n",
    "loop = tqdm(total=len(train_loader) * num_epochs, position=0)\n",
    "\n",
    "for epoch in range(num_epochs): # runs num_epochs number of times: each epoch runs\n",
    "                                # through one batch of data\n",
    "  \n",
    "  # ---training loop start\n",
    "  for i, (x, y_truth) in enumerate(train_loader): # each loop here steps through one batch\n",
    "    x, y_truth = x.cuda(async=True), y_truth.cuda(async=True) #async=True speeds it up\n",
    "\n",
    "    # forget about the gradients from before\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    y_hat = model(x)\n",
    "    train_loss = objective(y_hat, y_truth) # this is a way \n",
    "        \n",
    "    # display the information as you train\n",
    "    loop.set_description('loss:{:4f}'.format(train_loss.item()))\n",
    "    loop.update(1)\n",
    "\n",
    "    train_loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "  # ---training loop ends  \n",
    "    \n",
    "  # ---checking loop start  \n",
    "  for i, (x, y_truth) in enumerate(check_loader): # each loop here steps through one batch\n",
    "    x, y_truth = x.cuda(async=True), y_truth.cuda(async=True) #async=True speeds it up\n",
    "    y_hat = model(x)\n",
    "    check_loss = objective(y_hat, y_truth)\n",
    "  # ---checking loop ends\n",
    "  \n",
    "  train_losses.append(train_loss.item())\n",
    "  check_losses.append(check_loss.item())\n",
    "  \n",
    "loop.close()\n",
    "\n",
    "\n",
    "#  Plot the resulting loss curves\n",
    "plt.plot(train_losses, label = \"train\")\n",
    "plt.plot(check_losses, label = \"check\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_IZmHOvirnFn"
   },
   "source": [
    "\n",
    "___\n",
    "\n",
    "### Part 3\n",
    "Your notebook should extend the boilerplate code by adding a visualization of test/training\n",
    "performance over time. Use matplotlib.pyplot\n",
    "\n",
    "**TODO:**\n",
    "\n",
    "**DONE:**\n",
    "* Add a visualization of test/train performance (i.e. loss) over time.\n",
    "\n",
    "**SEE ABOVE**\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Edited_DL_Lab2.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
